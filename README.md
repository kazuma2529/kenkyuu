# 3D Particle Analysis Pipeline

A comprehensive pipeline for analyzing 3D particle structures from CT slice images, specifically designed for flan casting sand analysis.

## ğŸ¯ Overview

This pipeline processes CT slice images to:

1. **Clean and enhance masks** using CLAHE, Gaussian blur, and Otsu thresholding
2. **Create 3D volumes** from 2D mask stacks
3. **Split touching particles** using erosion-watershed algorithm
4. **Count particle contacts** with 26-connectivity analysis
5. **Generate statistical analysis** and visualizations

## ğŸ“Š Results Summary

- **Evaluation**: Dice coefficient = 0.930 (excellent mask quality)
- **Detection**: 1,174 particles identified from 196 CT slices
- **Contacts**: Mean = 1.61, Median = 1.0, Max = 19 contacts per particle
- **Processing time**: ~5 minutes for full dataset

## ğŸ—ï¸ Project Structure

```
â”œâ”€â”€ src/                          # Core package
â”‚   â”œâ”€â”€ particle_analysis/        # Main analysis modules
â”‚   â”‚   â”œâ”€â”€ processing.py         # Image processing and mask cleaning
â”‚   â”‚   â”œâ”€â”€ volume_ops.py         # 3D volume operations and particle splitting
â”‚   â”‚   â”œâ”€â”€ contact_analysis.py   # Contact counting and analysis
â”‚   â”‚   â””â”€â”€ evaluation.py         # Evaluation metrics (Dice, IoU)
â”‚   â”œâ”€â”€ utils/                    # Utility functions
â”‚   â”‚   â””â”€â”€ common.py            # Logging, timers, file operations
â”‚   â””â”€â”€ config.py                # Configuration management
â”œâ”€â”€ scripts/                      # Command-line scripts
â”‚   â”œâ”€â”€ run_pipeline.py          # Main pipeline orchestrator
â”‚   â””â”€â”€ evaluate_baseline.py     # Baseline evaluation script
â”œâ”€â”€ tests/                       # Test suite
â”‚   â””â”€â”€ test_pipeline_end2end.py # End-to-end integration tests
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Run Full Pipeline

```bash
# Basic usage with default settings
python scripts/run_pipeline.py \
    --img_dir data/images \
    --mask_dir data/masks_otsu \
    --output_dir output

# With custom erosion radius and verbose output
python scripts/run_pipeline.py \
    --img_dir data/images \
    --mask_dir data/masks_otsu \
    --output_dir output \
    --erosion_radius 3 \
    --verbose
```

### 3. Evaluate Against Ground Truth

```bash
python scripts/evaluate_baseline.py \
    --img_dir data/images \
    --mask_dir data/masks_otsu \
    --gt_dir data/ground_truth \
    --out_csv evaluation_results.csv
```

## ğŸ“‹ Command Reference

| Script                 | Purpose                | Key Options                     |
| ---------------------- | ---------------------- | ------------------------------- |
| `run_pipeline.py`      | Full analysis pipeline | `--erosion_radius`, `--verbose` |
| `evaluate_baseline.py` | Mask evaluation        | `--gt_dir`, `--out_csv`         |

### Pipeline Options

- `--img_dir`: Directory containing CT images (default: `data/images`)
- `--mask_dir`: Directory containing input masks (default: `data/masks_otsu`)
- `--output_dir`: Base output directory (default: `output`)
- `--erosion_radius`: Erosion radius for particle splitting (default: 2)
- `--verbose`: Enable detailed logging
- `--config`: Custom configuration file (YAML)

## ğŸ“ Output Structure

```
output/run_YYYYMMDD_HHMM/
â”œâ”€â”€ masks_pred/              # Processed masks
â”œâ”€â”€ volume.npy              # 3D boolean volume
â”œâ”€â”€ labels_r2.npy           # Labeled particles (radius=2)
â”œâ”€â”€ contact_counts.csv      # Per-particle contact counts
â”œâ”€â”€ contacts_summary.csv    # Statistical summary
â””â”€â”€ hist_contacts.png       # Contact distribution histogram
```

## ğŸ”¬ Algorithm Details

### 1. Mask Processing

- **CLAHE**: Contrast enhancement with configurable clip limit
- **Gaussian Blur**: Noise reduction
- **Otsu Thresholding**: Automatic binary segmentation
- **Morphological Operations**: Small object removal and closing

### 2. Particle Splitting

- **Erosion**: Separate touching particles (configurable radius)
- **Watershed**: Restore original particle boundaries
- **Connectivity**: 6-connected or 26-connected labeling

### 3. Contact Analysis

- **26-Connectivity**: Comprehensive neighbor scanning
- **Duplicate Removal**: Bidirectional contact counting
- **Statistical Analysis**: Mean, median, quartiles, outlier detection

## ğŸ§ª Testing

```bash
# Run end-to-end tests
python tests/test_pipeline_end2end.py

# Test individual modules
python -c "from src.particle_analysis.processing import clean_mask; print('Import successful')"
```

## ğŸ”§ Configuration

The pipeline uses a hierarchical configuration system. Create a YAML file to customize parameters:

```yaml
postprocess:
  clahe_clip_limit: 2.0
  gaussian_kernel: [3, 3]
  min_object_size: 100

splitting:
  erosion_radius: 2
  connectivity: 6
  min_particles: 100
  max_particles: 5000

contact:
  auto_exclude_threshold: 1000
```

## ğŸ“ˆ Performance Metrics

- **Processing Speed**: ~30 slices/second
- **Memory Usage**: ~2GB for 196 slices (512Ã—512)
- **Accuracy**: Dice = 0.930 vs ground truth
- **Particle Detection**: 1000+ particles from initially merged structures

## ğŸ› ï¸ Troubleshooting

### Common Issues

1. **Import Errors**: Ensure `src/` is in Python path
2. **Memory Issues**: Reduce batch size or image resolution
3. **No Particles Detected**: Check erosion radius (try smaller values)
4. **Contact Analysis Fails**: Verify particle labels are non-zero

### Debug Tips

- Use `--verbose` flag for detailed logging
- Check intermediate outputs in timestamped directories
- Verify input data format (PNG masks, proper naming)

## ğŸ“š Dependencies

- **Core**: numpy, scipy, scikit-image, opencv-python
- **Analysis**: pandas, matplotlib
- **UI**: tqdm (progress bars)
- **Testing**: unittest (built-in)

## ğŸ¤ Contributing

1. Follow the existing package structure
2. Add tests for new functionality
3. Update documentation
4. Use type hints and docstrings

## ğŸ“„ License

This project is part of 3D particle analysis research. Please cite appropriately if used in academic work.

---

**Status**: Production Ready âœ…  
**Last Updated**: 2025-06-18  
**Version**: 1.0.0

## ğŸ–¥ï¸ Interactive 3-D Viewing (napari)

Install optional dependency:

```bash
pip install "napari[all]"
```

### Launch viewer directly

```bash
python scripts/view_volume.py \
    --volume output/run_*/volume.npy \
    --labels output/run_*/labels_r2.npy \
    --rendering mip   # mip | attenuated_mip | iso
```

### Launch viewer automatically after pipeline

```bash
python scripts/run_pipeline.py \
    --img_dir data/images \
    --mask_dir data/masks_otsu \
    --interactive   # â† ã“ã‚Œã‚’ä»˜ã‘ã‚‹ã ã‘
```

æ“ä½œæ–¹æ³•:

- ãƒã‚¦ã‚¹ãƒ‰ãƒ©ãƒƒã‚°: å›è»¢
- ãƒ›ã‚¤ãƒ¼ãƒ«: ã‚ºãƒ¼ãƒ 
- å³ã‚¯ãƒªãƒƒã‚¯+ãƒ‰ãƒ©ãƒƒã‚°: å¹³è¡Œç§»å‹•
- ãƒ©ãƒ™ãƒ«ãƒ¬ã‚¤ãƒ¤ã‚’å·¦ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ **StatusBar ã«ç²’å­ ID** ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
